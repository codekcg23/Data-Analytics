{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python376jvsc74a57bd0fbbb7d2143a1d68e1cf272edf0974e702b621cb99b4ee39ce84db3bf0ffb588e",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# TF-IDF - Term Frequency  -Inverse Document Frequency"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Import Libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "source": [
    "## Read documents into document of list"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['1', '2', '3', '4', '5', 'Query']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0% which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully-connected layers we employed a recently-developed regularization method called “dropout” that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.'"
      ]
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "source": [
    "path = 'G:/Github/Data-Analytics/Assingments/Assingment1/Data/'\n",
    "docs = []\n",
    "fileList = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "print(fileList)\n",
    "for f in fileList:\n",
    "    doc = open(path+f,'r', encoding='utf8')\n",
    "    docs.append(doc.read())\n",
    "docs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INitialize vectorizer\n",
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "source": [
    "## Method 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = vectorizer.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "metrics  -  0.0616704415383249\nthree  -  0.042695212775252865\nall  -  0.0616704415383249\nstandard  -  0.0616704415383249\nfacto  -  0.0616704415383249\nde  -  0.0616704415383249\nthan  -  0.042695212775252865\nbetter  -  0.05057064426932227\nperforms  -  0.0616704415383249\nscheme  -  0.0616704415383249\nproper  -  0.0616704415383249\nfound  -  0.0616704415383249\nfurther  -  0.0616704415383249\n06  -  0.0616704415383249\nengine  -  0.0616704415383249\ntrading  -  0.0616704415383249\nsimulated  -  0.0616704415383249\nreturn  -  0.1233408830766498\nhighest  -  0.0616704415383249\naccuracy  -  0.0616704415383249\ndirectional  -  0.0616704415383249\n57  -  0.0616704415383249\nas  -  0.05057064426932227\nmovement  -  0.0616704415383249\ndirection  -  0.0616704415383249\nsame  -  0.0616704415383249\n04261  -  0.0616704415383249\nmse  -  0.0616704415383249\nfuture  -  0.1233408830766498\nactual  -  0.0616704415383249\ncloseness  -  0.0616704415383249\nin  -  0.07317310705901041\nperformance  -  0.0616704415383249\nbest  -  0.042695212775252865\nhad  -  0.0616704415383249\nrelease  -  0.0616704415383249\ntime  -  0.0616704415383249\nat  -  0.05057064426932227\nterms  -  0.0616704415383249\nboth  -  0.0616704415383249\nmodel  -  0.05057064426932227\nthat  -  0.06319083101250048\nshow  -  0.0616704415383249\nvariables  -  0.0616704415383249\nspecific  -  0.0616704415383249\ncontaining  -  0.1233408830766498\nmodels  -  0.0616704415383249\nprediction  -  0.0616704415383249\nnumeric  -  0.0616704415383249\ntailored  -  0.0616704415383249\nspecially  -  0.0616704415383249\nderivative  -  0.0616704415383249\nsvm  -  0.0616704415383249\nvector  -  0.0616704415383249\nsupport  -  0.0616704415383249\nreleased  -  0.0616704415383249\nwas  -  0.0616704415383249\narticle  -  0.1850113246149747\nafter  -  0.0616704415383249\nminutes  -  0.0616704415383249\ntwenty  -  0.0616704415383249\nprice  -  0.30835220769162447\ndiscrete  -  0.1233408830766498\nestimate  -  0.0616704415383249\nto  -  0.06319083101250048\napplied  -  0.0616704415383249\nperiod  -  0.0616704415383249\nweek  -  0.0616704415383249\nfive  -  0.042695212775252865\nduring  -  0.0616704415383249\nstocks  -  0.0616704415383249\n500  -  0.0616704415383249\nthe  -  0.31595415506250235\ncovering  -  0.0616704415383249\nquotes  -  0.0616704415383249\nstock  -  0.30835220769162447\n042  -  0.0616704415383249\n259  -  0.0616704415383249\n10  -  0.0616704415383249\n211  -  0.0616704415383249\ninvestigated  -  0.1233408830766498\nwe  -  0.12638166202500095\nthis  -  0.05057064426932227\nthrough  -  0.05057064426932227\nentities  -  0.0616704415383249\nnamed  -  0.0616704415383249\nand  -  0.16425281061730582\nphrases  -  0.0616704415383249\nnoun  -  0.1233408830766498\nwords  -  0.1233408830766498\nof  -  0.13687734218108819\nbag  -  0.1233408830766498\nrepresentations  -  0.1233408830766498\ntextual  -  0.1233408830766498\ndifferent  -  0.1280856383257586\nseveral  -  0.0616704415383249\nusing  -  0.1280856383257586\nanalysis  -  0.1233408830766498\narticles  -  0.1233408830766498\nnews  -  0.1850113246149747\nfinancial  -  0.10114128853864454\nfor  -  0.1233408830766498\napproach  -  0.1233408830766498\nlearning  -  0.0616704415383249\nmachine  -  0.1233408830766498\npredictive  -  0.0616704415383249\nexamines  -  0.0616704415383249\nresearch  -  0.0616704415383249\nour  -  0.10114128853864454\nentry  -  0.0\nsecond  -  0.0\n26  -  0.0\ncompared  -  0.0\n15  -  0.0\nrate  -  0.0\nwinning  -  0.0\ncompetition  -  0.0\n2012  -  0.0\nilsvrc  -  0.0\nvariant  -  0.0\nentered  -  0.0\nalso  -  0.0\neffective  -  0.0\nbe  -  0.0\nproved  -  0.0\ndropout  -  0.0\ncalled  -  0.0\nmethod  -  0.0\nregularization  -  0.0\ndeveloped  -  0.0\nrecently  -  0.0\nemployed  -  0.0\noverfitting  -  0.0\nreduce  -  0.0\noperation  -  0.0\nconvolution  -  0.0\nimplementation  -  0.0\ngpu  -  0.0\nefficient  -  0.0\nvery  -  0.0\nsaturating  -  0.0\nnon  -  0.0\nused  -  0.0\nfaster  -  0.0\ntraining  -  0.0\nmake  -  0.0\nsoftmax  -  0.0\nway  -  0.0\nfinal  -  0.0\nwith  -  0.0\nconnected  -  0.0\nfully  -  0.0\npooling  -  0.0\nmax  -  0.0\nby  -  0.0\nfollowed  -  0.0\nare  -  0.0\nsome  -  0.0\nlayers  -  0.0\nconsists  -  0.0\nneurons  -  0.0\n000  -  0.0\n650  -  0.0\nparameters  -  0.0\n60  -  0.0\nhas  -  0.0\nart  -  0.0\nstate  -  0.0\nprevious  -  0.0\nconsiderably  -  0.0\nis  -  0.0\nwhich  -  0.0\n17  -  0.0\n37  -  0.0\nrates  -  0.0\nerror  -  0.0\ntop  -  0.0\nachieved  -  0.0\ndata  -  0.0\ntest  -  0.0\non  -  0.0\nclasses  -  0.0\n1000  -  0.0\ninto  -  0.0\ncontest  -  0.0\n2010  -  0.0\nlsvrc  -  0.0\nimagenet  -  0.0\nimages  -  0.0\nresolution  -  0.0\nhigh  -  0.0\nmillion  -  0.0\nclassify  -  0.0\nnetwork  -  0.0\nneural  -  0.0\nconvolutional  -  0.0\ndeep  -  0.0\nlarge  -  0.0\ntrained  -  0.0\nthree  -  0.042695212775252865\nthan  -  0.042695212775252865\nbetter  -  0.05057064426932227\nin  -  0.07317310705901041\nbest  -  0.042695212775252865\nmodel  -  0.05057064426932227\nthat  -  0.06319083101250048\nto  -  0.06319083101250048\nfive  -  0.042695212775252865\nthe  -  0.31595415506250235\nwe  -  0.12638166202500095\nthis  -  0.05057064426932227\nand  -  0.16425281061730582\nof  -  0.13687734218108819\ndifferent  -  0.1280856383257586\ngone  -  0.0\nwere  -  0.0\nwhile  -  0.0\nhappened  -  0.0\nwhat  -  0.0\naccepting  -  0.0\nwill  -  0.0\nrejoin  -  0.0\nleave  -  0.0\ncan  -  0.0\nbasis  -  0.0\neffort  -  0.0\nbroadcast  -  0.0\nmessages  -  0.0\nstructure  -  0.0\nminimal  -  0.0\nrequires  -  0.0\nitself  -  0.0\nattackers  -  0.0\noutpace  -  0.0\ngenerate  -  0.0\nll  -  0.0\nthey  -  0.0\nattack  -  0.0\ncooperating  -  0.0\nnodes  -  0.0\ncontrolled  -  0.0\nmajority  -  0.0\nlong  -  0.0\npower  -  0.0\ncpu  -  0.0\npool  -  0.0\nlargest  -  0.0\ncame  -  0.0\nit  -  0.0\nwitnessed  -  0.0\nevents  -  0.0\nsequence  -  0.0\nserves  -  0.0\nonly  -  0.0\nnot  -  0.0\nlongest  -  0.0\nredoing  -  0.0\nchanged  -  0.0\ncannot  -  0.0\nrecord  -  0.0\nforming  -  0.0\nwork  -  0.0\nproof  -  0.0\nbased  -  0.0\nhash  -  0.0\nchain  -  0.0\nongoing  -  0.0\nan  -  0.0\nthem  -  0.0\nhashing  -  0.0\ntransactions  -  0.0\ntimestamps  -  0.0\nproblem  -  0.0\npropose  -  0.0\nspending  -  0.0\ndouble  -  0.0\nprevent  -  0.0\nrequired  -  0.0\nstill  -  0.0\nthird  -  0.0\ntrusted  -  0.0\nif  -  0.0\nlost  -  0.0\nbenefits  -  0.0\nmain  -  0.0\nbut  -  0.0\nsolution  -  0.0\npart  -  0.0\nprovide  -  0.0\nsignatures  -  0.0\ndigital  -  0.0\ninstitution  -  0.0\ngoing  -  0.0\nwithout  -  0.0\nanother  -  0.0\nparty  -  0.0\none  -  0.0\nfrom  -  0.0\ndirectly  -  0.0\nsent  -  0.0\npayments  -  0.0\nonline  -  0.0\nallow  -  0.0\nwould  -  0.0\ncash  -  0.0\nelectronic  -  0.0\nversion  -  0.0\npeer  -  0.0\npurely  -  0.0\nbe  -  0.0\nby  -  0.0\nare  -  0.0\nis  -  0.0\non  -  0.0\ninto  -  0.0\nnetwork  -  0.0\nas  -  0.05057064426932227\nbest  -  0.042695212775252865\nat  -  0.05057064426932227\nthat  -  0.06319083101250048\nto  -  0.06319083101250048\nthe  -  0.31595415506250235\nwe  -  0.12638166202500095\nthrough  -  0.05057064426932227\nand  -  0.16425281061730582\nof  -  0.13687734218108819\nusing  -  0.1280856383257586\nfinancial  -  0.10114128853864454\nindividuals  -  0.0\nsymptomatic  -  0.0\ntransmission  -  0.0\ncould  -  0.0\nindicate  -  0.0\nresults  -  0.0\ntoward  -  0.0\ntrend  -  0.0\naerosols  -  0.0\ncoronavirus  -  0.0\ndroplets  -  0.0\nrna  -  0.0\nvirus  -  0.0\ndetection  -  0.0\nreduced  -  0.0\nsignificantly  -  0.0\nmasks  -  0.0\nface  -  0.0\nsurgical  -  0.0\nillness  -  0.0\nrespiratory  -  0.0\nacute  -  0.0\nadults  -  0.0\nchildren  -  0.0\ncoughs  -  0.0\nbreath  -  0.0\nexhaled  -  0.0\nrhinoviruses  -  0.0\nviruses  -  0.0\ninfluenza  -  0.0\ncoronaviruses  -  0.0\nhuman  -  0.0\nseasonal  -  0.0\nidentified  -  0.0\nprevent  -  0.0\nfrom  -  0.0\nwith  -  0.0\nin  -  0.07317310705901041\nthat  -  0.06319083101250048\nwe  -  0.12638166202500095\nand  -  0.16425281061730582\nof  -  0.13687734218108819\nour  -  0.10114128853864454\n1014  -  0.0\nfactor  -  0.0\nsupercomputers  -  0.0\nstrategy  -  0.0\nsimulation  -  0.0\n1030  -  0.0\ndimension  -  0.0\nspace  -  0.0\nyields  -  0.0\nclicks  -  0.0\n76  -  0.0\nup  -  0.0\ngenerates  -  0.0\njiuzhang  -  0.0\ncomputer  -  0.0\nphotonic  -  0.0\ndistribution  -  0.0\nuniform  -  0.0\nphotons  -  0.0\ndistinguishable  -  0.0\nthermal  -  0.0\nexploiting  -  0.0\nhypotheses  -  0.0\nplausible  -  0.0\nagainst  -  0.0\nvalidated  -  0.0\nsamples  -  0.0\nobtained  -  0.0\ndetectors  -  0.0\nphoton  -  0.0\nefficiency  -  0.0\noutput  -  0.0\nlocked  -  0.0\nphase  -  0.0\nsetup  -  0.0\noptical  -  0.0\nwhole  -  0.0\nmatrix  -  0.0\nrandom  -  0.0\nconnectivity  -  0.0\nfull  -  0.0\ninterferometer  -  0.0\nloss  -  0.0\nultralow  -  0.0\n100  -  0.0\nstates  -  0.0\nsqueezed  -  0.0\nmode  -  0.0\nsingle  -  0.0\nindistinguishable  -  0.0\n50  -  0.0\nsending  -  0.0\ngaussian  -  0.0\nperformed  -  0.0\nadvantage  -  0.0\ncomputational  -  0.0\ndemonstrate  -  0.0\ncandidate  -  0.0\nstrong  -  0.0\nconsidered  -  0.0\ntask  -  0.0\nsuch  -  0.0\nsampling  -  0.0\nboson  -  0.0\nclassical  -  0.0\nintractable  -  0.0\nbelieved  -  0.0\ntasks  -  0.0\ncertain  -  0.0\nperform  -  0.0\npromise  -  0.0\ncomputers  -  0.0\nquantum  -  0.0\nwere  -  0.0\nan  -  0.0\nrate  -  0.0\nbe  -  0.0\nfaster  -  0.0\nwith  -  0.0\nby  -  0.0\nare  -  0.0\nart  -  0.0\nstate  -  0.0\nis  -  0.0\nwhich  -  0.0\ninto  -  0.0\nhigh  -  0.0\nthan  -  0.042695212775252865\nthat  -  0.06319083101250048\nto  -  0.06319083101250048\nthe  -  0.31595415506250235\nwe  -  0.12638166202500095\nand  -  0.16425281061730582\nof  -  0.13687734218108819\nusing  -  0.1280856383257586\nsoftmax  -  0.0\nway  -  0.0\nfinal  -  0.0\nwith  -  0.0\nconnected  -  0.0\nfully  -  0.0\npooling  -  0.0\nmax  -  0.0\nby  -  0.0\nfollowed  -  0.0\nare  -  0.0\nsome  -  0.0\nlayers  -  0.0\nconsists  -  0.0\nneurons  -  0.0\n000  -  0.0\n650  -  0.0\nparameters  -  0.0\n60  -  0.0\nhas  -  0.0\nwhich  -  0.0\nclasses  -  0.0\n1000  -  0.0\ninto  -  0.0\ncontest  -  0.0\n2010  -  0.0\nlsvrc  -  0.0\nimagenet  -  0.0\nimages  -  0.0\nresolution  -  0.0\nhigh  -  0.0\nmillion  -  0.0\nclassify  -  0.0\nnetwork  -  0.0\nneural  -  0.0\nconvolutional  -  0.0\ndeep  -  0.0\ntrained  -  0.0\nthree  -  0.042695212775252865\nin  -  0.07317310705901041\nto  -  0.06319083101250048\nfive  -  0.042695212775252865\nthe  -  0.31595415506250235\nand  -  0.16425281061730582\nof  -  0.13687734218108819\ndifferent  -  0.1280856383257586\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "for col in response.nonzero()[1]:\n",
    "    print (feature_names[col], ' - ', response[0, col])"
   ]
  },
  {
   "source": [
    "## TF-IDF weights"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            000      042    04261       06       10      100      1000  \\\n",
       "1      0.000000  0.06167  0.06167  0.06167  0.06167  0.00000  0.000000   \n",
       "2      0.058272  0.00000  0.00000  0.00000  0.00000  0.00000  0.116545   \n",
       "3      0.000000  0.00000  0.00000  0.00000  0.00000  0.00000  0.000000   \n",
       "4      0.000000  0.00000  0.00000  0.00000  0.00000  0.00000  0.000000   \n",
       "5      0.000000  0.00000  0.00000  0.00000  0.00000  0.15135  0.000000   \n",
       "Query  0.125709  0.00000  0.00000  0.00000  0.00000  0.00000  0.251418   \n",
       "\n",
       "           1014      1030        15  ...     whole      will   winning  \\\n",
       "1      0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "2      0.000000  0.000000  0.071063  ...  0.000000  0.000000  0.071063   \n",
       "3      0.000000  0.000000  0.000000  ...  0.000000  0.055022  0.000000   \n",
       "4      0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "5      0.075675  0.075675  0.000000  ...  0.075675  0.000000  0.000000   \n",
       "Query  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "\n",
       "           with   without  witnessed     words      work     would    yields  \n",
       "1      0.000000  0.000000   0.000000  0.123341  0.000000  0.000000  0.000000  \n",
       "2      0.042159  0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3      0.000000  0.110043   0.055022  0.000000  0.165065  0.055022  0.000000  \n",
       "4      0.115430  0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "5      0.044895  0.000000   0.000000  0.000000  0.000000  0.000000  0.075675  \n",
       "Query  0.090947  0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[6 rows x 401 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>000</th>\n      <th>042</th>\n      <th>04261</th>\n      <th>06</th>\n      <th>10</th>\n      <th>100</th>\n      <th>1000</th>\n      <th>1014</th>\n      <th>1030</th>\n      <th>15</th>\n      <th>...</th>\n      <th>whole</th>\n      <th>will</th>\n      <th>winning</th>\n      <th>with</th>\n      <th>without</th>\n      <th>witnessed</th>\n      <th>words</th>\n      <th>work</th>\n      <th>would</th>\n      <th>yields</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.06167</td>\n      <td>0.06167</td>\n      <td>0.06167</td>\n      <td>0.06167</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.123341</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.058272</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.116545</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.071063</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.071063</td>\n      <td>0.042159</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.055022</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.110043</td>\n      <td>0.055022</td>\n      <td>0.000000</td>\n      <td>0.165065</td>\n      <td>0.055022</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.115430</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.15135</td>\n      <td>0.000000</td>\n      <td>0.075675</td>\n      <td>0.075675</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.075675</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.044895</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.075675</td>\n    </tr>\n    <tr>\n      <th>Query</th>\n      <td>0.125709</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.251418</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.090947</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>6 rows × 401 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "df = pd.DataFrame(response.todense(), columns=feature_names, index=fileList)\n",
    "df\n",
    "        "
   ]
  },
  {
   "source": [
    "## Find cosine similarity"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.149704  , 0.66069765, 0.1864068 , 0.08439114, 0.15741387,\n",
       "        1.        ]])"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity(response[-1],response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.149704  , 0.66069765, 0.1864068 , 0.08439114, 0.15741387,\n",
       "       1.        ])"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "cosine_similarities = linear_kernel(response[-1], response).flatten()\n",
    "cosine_similarities"
   ]
  },
  {
   "source": [
    "## Most Similar document to given query"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Most similar document file =  2  and it's similarity score =  0.6606976458297944\n\nMost Similar Document \n\nWe trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0% which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully-connected layers we employed a recently-developed regularization method called “dropout” that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.\n\nQuery Document \n\n Trained deep convolutional neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a final 1000-way softmax to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. \n\n"
     ]
    }
   ],
   "source": [
    "print(\"Most similar document file = \",fileList[np.where(cosine_similarities == max(cosine_similarities[:4]))[0][0]],\" and it's similarity score = \", max(cosine_similarities[:4]))\n",
    "print(\"\\n Most Similar Document \\n\\n\"+docs[np.where(cosine_similarities == max(cosine_similarities[:4]))[0][0]])\n",
    "print(\"\\n Query Document \\n\\n\", docs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cosine_sim(doc, query):\n",
    "#     tfidf = vectorizer.fit_transform([doc,query])\n",
    "#     return ((tfidf * tfidf.T).A)[0,1]"
   ]
  }
 ]
}